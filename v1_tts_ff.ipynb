{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "open_ai_key=\n",
    "\n",
    "llm_openai_4o_128k = OpenAI(model=\"gpt-4o-mini\", api_key=open_ai_key)\n",
    "\n",
    "llm_openai_o3_200k = OpenAI(model=\"o3-mini-2025-01-31\", api_key=open_ai_key)\n",
    "\n",
    "# print(llm_openai_o3_200k.complete(\"Paul Graham is \"))\n",
    "# print(llm_openai_4o_128k.complete(\"Paul Graham is \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.llms.bedrock import Bedrock\n",
    "\n",
    "llm_claude_3_5_200k = Bedrock(\n",
    "    model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    aws_access_key_id=\"AKIAUFH6ATMKNLAFBT6V\",\n",
    "    aws_secret_access_key=\"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\",\n",
    "    region_name=\"us-east-1\",\n",
    "    temperature=0,\n",
    "    context_size=200000,\n",
    "    )\n",
    "\n",
    "# print(llm_claude_3_5_200k.complete(\"Paul Graham is \"))\n",
    "\n",
    "\n",
    "llm_mistral_large_32k = Bedrock(\n",
    "    model=\"mistral.mistral-large-2402-v1:0\",\n",
    "    aws_access_key_id=\"AKIAUFH6ATMKNLAFBT6V\",\n",
    "    aws_secret_access_key=\"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\",\n",
    "    region_name=\"us-east-1\",\n",
    "    temperature=0,\n",
    "    context_size=32000,\n",
    "    )\n",
    "\n",
    "# print(llm_mistral_large_32k.complete(\"Paul Graham is \"))\n",
    "\n",
    "\n",
    "llm_mistral_8x7_32k = Bedrock(\n",
    "    model=\"mistral.mixtral-8x7b-instruct-v0:1\",\n",
    "    aws_access_key_id=\"AKIAUFH6ATMKNLAFBT6V\",\n",
    "    aws_secret_access_key=\"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\",\n",
    "    region_name=\"us-east-1\",\n",
    "    temperature=0,\n",
    "    context_size=32000,\n",
    "    )\n",
    "\n",
    "# print(llm_mistral_8x7_32k.complete(\"Paul Graham is \"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sqlalchemy import create_engine, inspect, text\n",
    "\n",
    "# database_url = \"mysql+pymysql://golgix:preciseV5@143.198.230.83:3306/golgixportal\"\n",
    "# engine = create_engine(database_url)\n",
    "\n",
    "def get_first_row_with_types(inspector, tables):\n",
    "    result_str = \"\"\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        for table in tables:\n",
    "            if table in inspector.get_table_names():\n",
    "                # Get column details\n",
    "                columns = inspector.get_columns(table)\n",
    "                column_info = {col[\"name\"]: str(col[\"type\"]) for col in columns}\n",
    "                \n",
    "                # Get first row data\n",
    "                query = text(f\"SELECT * FROM `{table}` LIMIT 1\")\n",
    "                row = conn.execute(query).fetchone()\n",
    "                \n",
    "                # Format results as string\n",
    "                result_str += f\"Table: {table}\\n\"\n",
    "                result_str += f\"Columns and Data Types: {column_info}\\n\"\n",
    "                result_str += f\"First Row: {dict(zip(column_info.keys(), row)) if row else None}\\n\"\n",
    "                result_str += \"-\" * 50 + \"\\n\"\n",
    "    \n",
    "    return result_str\n",
    "\n",
    "# Example usage\n",
    "# inspector = inspect(engine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: DE\n",
      "Columns and Data Types: {'recordid': 'INTEGER', 'datetime': 'DATETIME', 'date': 'DATE', 'shift': 'VARCHAR(50)', 'operator': 'VARCHAR(50)', 'hour': 'VARCHAR(100)', 'category': 'VARCHAR(50)', 'parameter': 'VARCHAR(50)', 'target': 'VARCHAR(50)', 'entered_value': 'VARCHAR(50)', 'user': 'VARCHAR(50)'}\n",
      "First Row: {'recordid': 34, 'datetime': datetime.datetime(2024, 12, 12, 5, 13, 27), 'date': datetime.date(2024, 12, 11), 'shift': 'B', 'operator': 'DYLAN EVANS_1', 'hour': '8:30', 'category': 'EVAP', 'parameter': 'Draw Pump', 'target': '4.9', 'entered_value': '5', 'user': 'admin'}\n",
      "--------------------------------------------------\n",
      "Table: HPLC_Data\n",
      "Columns and Data Types: {'Quarter': 'VARCHAR(10)', 'Ferm Drop Month': 'VARCHAR(20)', 'Ferm No': 'VARCHAR(10)', 'Batch No': 'VARCHAR(20)', 'Ferm Hour': 'VARCHAR(50)', 'Sample Description': 'VARCHAR(50)', 'Prop Mash % Solids': 'FLOAT', 'Prop Urea (lbs)': 'FLOAT', 'Prop Antibiotic (lbs)': 'FLOAT', 'Prop GA (gal)': 'FLOAT', 'Prop Protease (gal)': 'FLOAT', 'Ferm GA 1st Add. (gal)': 'FLOAT', 'Ferm GA 2nd Add (gal)': 'FLOAT', 'Ferm GA Flow (mL/min)': 'FLOAT', 'Ferm Fill Time (hrs)': 'FLOAT', 'GA Meter Add. (gal)': 'FLOAT', 'Total Ferm GA (gal)': 'FLOAT', 'Ferm AA Flow (mL/min)': 'FLOAT', 'Ferm AA (gal)': 'FLOAT', 'Ferm Protease (gal)': 'FLOAT', 'Ferm Phytase (gal)': 'FLOAT', 'Ferm Antibiotic (lbs)': 'FLOAT', 'Ferm Liq Urea (gal)': 'FLOAT', 'Ferm Prilled Urea (lbs)': 'FLOAT', 'First Yeast Addition (Boxes)': 'FLOAT', 'Second Yeast Addition (boxes)': 'FLOAT', 'Prop Start Date and Time': 'DATETIME', 'Start Fill Date and Time': 'DATETIME', 'Drop Date and Time': 'DATETIME', '% Backset to Ferm': 'FLOAT', 'Slurry Density (lbs/gal)': 'FLOAT', 'Liq Density (lbs/gal)': 'FLOAT', 'Prop hours': 'FLOAT', 'pH': 'FLOAT', 'Brix': 'FLOAT', 'Prop Temp (F)': 'FLOAT', 'Ferm Vessel Temp (F)': 'FLOAT', '% Budding': 'FLOAT', 'Cell Count': 'FLOAT', '% Viability': 'FLOAT', 'Total Cells Count (Calc)': 'FLOAT', 'Live Cells': 'FLOAT', 'Dead Cells': 'FLOAT', '% Viability (Calc)': 'FLOAT', '% DP4 (w/v)': 'FLOAT', '% DP3 (w/v)': 'FLOAT', '% DP2 (w/v)': 'FLOAT', '% Glucose (w/v)': 'FLOAT', '% Lactic Acid (w/v)': 'FLOAT', '% Glycerol (w/v)': 'FLOAT', '% Acetic Acid (w/v)': 'FLOAT', '% Ethanol (w/v)': 'FLOAT', '% Total Sugars (w/v)': 'FLOAT', 'Notes': 'TEXT'}\n",
      "First Row: {'Quarter': 'Q4', 'Ferm Drop Month': 'November', 'Ferm No': 'F1', 'Batch No': '8936', 'Ferm Hour': '5', 'Sample Description': 'PROP', 'Prop Mash % Solids': 19.85, 'Prop Urea (lbs)': 100.0, 'Prop Antibiotic (lbs)': 0.25, 'Prop GA (gal)': 0.5, 'Prop Protease (gal)': None, 'Ferm GA 1st Add. (gal)': 27.4, 'Ferm GA 2nd Add (gal)': 0.0, 'Ferm GA Flow (mL/min)': 0.0, 'Ferm Fill Time (hrs)': 13.75, 'GA Meter Add. (gal)': 0.0, 'Total Ferm GA (gal)': 27.4, 'Ferm AA Flow (mL/min)': 147.0, 'Ferm AA (gal)': 32.041, 'Ferm Protease (gal)': None, 'Ferm Phytase (gal)': 2.7, 'Ferm Antibiotic (lbs)': 2.0, 'Ferm Liq Urea (gal)': 733.0, 'Ferm Prilled Urea (lbs)': None, 'First Yeast Addition (Boxes)': 4.0, 'Second Yeast Addition (boxes)': None, 'Prop Start Date and Time': datetime.datetime(2024, 11, 6, 2, 30), 'Start Fill Date and Time': datetime.datetime(2024, 11, 6, 10, 30), 'Drop Date and Time': datetime.datetime(2024, 11, 8, 11, 30), '% Backset to Ferm': 14.0, 'Slurry Density (lbs/gal)': 9.33, 'Liq Density (lbs/gal)': 9.107, 'Prop hours': 8.0, 'pH': 5.04, 'Brix': 17.7, 'Prop Temp (F)': 89.6, 'Ferm Vessel Temp (F)': None, '% Budding': None, 'Cell Count': None, '% Viability': None, 'Total Cells Count (Calc)': 434.0, 'Live Cells': 368.0, 'Dead Cells': 66.0, '% Viability (Calc)': 0.847926, '% DP4 (w/v)': None, '% DP3 (w/v)': None, '% DP2 (w/v)': None, '% Glucose (w/v)': None, '% Lactic Acid (w/v)': None, '% Glycerol (w/v)': None, '% Acetic Acid (w/v)': None, '% Ethanol (w/v)': None, '% Total Sugars (w/v)': None, 'Notes': None}\n",
      "--------------------------------------------------\n",
      "Table: fermentation_data\n",
      "Columns and Data Types: {'id': 'INTEGER', 'age': 'VARCHAR(50)', 'date': 'VARCHAR(50)', 'am_pm': 'VARCHAR(25)', 'ph': 'VARCHAR(10)', 'brix': 'VARCHAR(10)', 'temp': 'VARCHAR(10)', 'total': 'VARCHAR(10)', 'live': 'VARCHAR(10)', 'dead': 'VARCHAR(10)', 'viability': 'VARCHAR(10)', 'dp4': 'VARCHAR(10)', 'dp3': 'VARCHAR(10)', 'dp2': 'VARCHAR(10)', 'glucose': 'VARCHAR(10)', 'total_sugars': 'VARCHAR(10)', 'lactic_acid': 'VARCHAR(10)', 'glycerol': 'VARCHAR(10)', 'acetic_acid': 'VARCHAR(10)', 'ethanol': 'VARCHAR(10)', 'tester_initials': 'VARCHAR(50)', 'notes': 'TEXT', 'date_of_start': 'VARCHAR(100)', 'time_of_start': 'VARCHAR(100)', 'batch_number': 'VARCHAR(100)', 'ferm_number': 'VARCHAR(100)'}\n",
      "First Row: {'id': 37, 'age': 'P-4', 'date': '1', 'am_pm': '', 'ph': '', 'brix': '', 'temp': '', 'total': '', 'live': '', 'dead': '', 'viability': '', 'dp4': '', 'dp3': '', 'dp2': '', 'glucose': '', 'total_sugars': '', 'lactic_acid': '', 'glycerol': '', 'acetic_acid': '', 'ethanol': '', 'tester_initials': '', 'notes': '', 'date_of_start': '2025-22-01', 'time_of_start': '01:02', 'batch_number': '123', 'ferm_number': '123'}\n",
      "--------------------------------------------------\n",
      "Table: plc_data_1\n",
      "Columns and Data Types: {'ID': 'INTEGER', 'Timestamp': 'DATETIME', 'Source_PLC': 'TEXT', 'AMM_3118_PV': 'DOUBLE', 'AMM_3118TOT_PV': 'DOUBLE', 'AMM_3128_PV': 'DOUBLE', 'AMM_3128TOT_PV': 'DOUBLE', 'AMM_3138_PV': 'DOUBLE', 'AMM_3138TOT_PV': 'DOUBLE', 'AMM_3148_PV': 'DOUBLE', 'AMM_3148TOT_PV': 'DOUBLE', 'DI_3130_PV': 'DOUBLE', 'FI_2402_PV': 'DOUBLE', 'FI_3150_PV': 'DOUBLE', 'FI_3155_PV': 'DOUBLE', 'FI_3610_PV': 'DOUBLE', 'FI_3801_PV': 'DOUBLE', 'FI_3802_PV': 'DOUBLE', 'FIC_3513_PV': 'DOUBLE', 'FIC_3513_SP': 'DOUBLE', 'FIC_3513_VL': 'DOUBLE', 'FIC_3801_PV': 'DOUBLE', 'FIC_3801_SP': 'DOUBLE', 'FIC_3801_VL': 'DOUBLE', 'FIC_3803_PV': 'DOUBLE', 'FIC_3803_SP': 'DOUBLE', 'FIC_3803_VL': 'DOUBLE', 'LI_3111_PV': 'DOUBLE', 'LI_3121_PV': 'DOUBLE', 'LI_3131_PV': 'DOUBLE', 'LI_3141_PV': 'DOUBLE', 'LI_3501_PV': 'DOUBLE', 'LI_3601_PV': 'DOUBLE', 'LIC_3801_PV': 'DOUBLE', 'LIC_3801_SP': 'DOUBLE', 'LIC_3801_VL': 'DOUBLE', 'pHIC_2402_PV': 'DOUBLE', 'pHIC_2402_SP': 'DOUBLE', 'pHIC_2402_VL': 'DOUBLE', 'pHIC_3501_PV': 'DOUBLE', 'pHIC_3501_SP': 'DOUBLE', 'pHIC_3501_VL': 'DOUBLE', 'PI_2402_PV': 'DOUBLE', 'PI_3801_PV': 'DOUBLE', 'TI_3112_PV': 'DOUBLE', 'TI_3113_PV': 'DOUBLE', 'TI_3122_PV': 'DOUBLE', 'TI_3123_PV': 'DOUBLE', 'TI_3132_PV': 'DOUBLE', 'TI_3133_PV': 'DOUBLE', 'TI_3142_PV': 'DOUBLE', 'TI_3143_PV': 'DOUBLE', 'TI_3501_PV': 'DOUBLE'}\n",
      "First Row: {'ID': 1, 'Timestamp': datetime.datetime(2024, 11, 24, 9, 28, 15), 'Source_PLC': 'plc_historian_db_1', 'AMM_3118_PV': 15.849609375, 'AMM_3118TOT_PV': 19.81201171875, 'AMM_3128_PV': 16.95027732849121, 'AMM_3128TOT_PV': 17.17041015625, 'AMM_3138_PV': None, 'AMM_3138TOT_PV': None, 'AMM_3148_PV': 25.09521484375, 'AMM_3148TOT_PV': 27.4066162109375, 'DI_3130_PV': None, 'FI_2402_PV': 678.6475219726562, 'FI_3150_PV': None, 'FI_3155_PV': 642.8986206054688, 'FI_3610_PV': -0.002201080322265625, 'FI_3801_PV': None, 'FI_3802_PV': 75.16288757324219, 'FIC_3513_PV': 585.4341430664062, 'FIC_3513_SP': 585.0, 'FIC_3513_VL': 68.8689956665039, 'FIC_3801_PV': 0.1739025115966797, 'FIC_3801_SP': 10.0, 'FIC_3801_VL': 0.0, 'FIC_3803_PV': 45.0145263671875, 'FIC_3803_SP': 45.0, 'FIC_3803_VL': 86.82141876220703, 'LI_3111_PV': 88.7095947265625, 'LI_3121_PV': 73.41251373291016, 'LI_3131_PV': 9.008627891540527, 'LI_3141_PV': 87.0737075805664, 'LI_3501_PV': 59.39183807373047, 'LI_3601_PV': 67.67308807373047, 'LIC_3801_PV': 40.131927490234375, 'LIC_3801_SP': 40.0, 'LIC_3801_VL': 55.33071517944336, 'pHIC_2402_PV': 5.14229154586792, 'pHIC_2402_SP': 4.699999809265137, 'pHIC_2402_VL': 100.0, 'pHIC_3501_PV': 4.381702899932861, 'pHIC_3501_SP': 5.0, 'pHIC_3501_VL': 13.0, 'PI_2402_PV': 52.90748977661133, 'PI_3801_PV': 9.678810119628906, 'TI_3112_PV': 85.20062255859375, 'TI_3113_PV': 65.28982543945312, 'TI_3122_PV': 89.2398452758789, 'TI_3123_PV': 65.16073608398438, 'TI_3132_PV': 90.2811508178711, 'TI_3133_PV': 91.61457824707031, 'TI_3142_PV': 85.01476287841797, 'TI_3143_PV': 65.31922912597656, 'TI_3501_PV': 91.72306823730469}\n",
      "--------------------------------------------------\n",
      "Table: plc_data_2\n",
      "Columns and Data Types: {'ID': 'INTEGER', 'Timestamp': 'DATETIME', 'Source_PLC': 'TEXT', 'TI_3801_PV': 'DOUBLE', 'TIC_3111_EXT_PV': 'DOUBLE', 'TIC_3111_EXT_SP': 'DOUBLE', 'TIC_3111_EXT_VL': 'DOUBLE', 'TIC_3111B_EXT_PV': 'DOUBLE', 'TIC_3111B_EXT_SP': 'DOUBLE', 'TIC_3111B_EXT_VL': 'DOUBLE', 'TIC_3121_EXT_PV': 'DOUBLE', 'TIC_3121_EXT_SP': 'DOUBLE', 'TIC_3121_EXT_VL': 'DOUBLE', 'TIC_3121B_EXT_PV': 'DOUBLE', 'TIC_3121B_EXT_SP': 'DOUBLE', 'TIC_3121B_EXT_VL': 'DOUBLE', 'TIC_3131_EXT_PV': 'DOUBLE', 'TIC_3131_EXT_SP': 'DOUBLE', 'TIC_3131_EXT_VL': 'DOUBLE', 'TIC_3131B_EXT_PV': 'DOUBLE', 'TIC_3131B_EXT_SP': 'DOUBLE', 'TIC_3131B_EXT_VL': 'DOUBLE', 'TIC_3141_EXT_PV': 'DOUBLE', 'TIC_3141_EXT_SP': 'DOUBLE', 'TIC_3141_EXT_VL': 'DOUBLE', 'TIC_3141B_EXT_PV': 'DOUBLE', 'TIC_3141B_EXT_SP': 'DOUBLE', 'TIC_3141B_EXT_VL': 'DOUBLE', 'TIC_3601_PV': 'DOUBLE', 'TIC_3601_SP': 'DOUBLE', 'TIC_3601_VL': 'DOUBLE', 'TIC_3602_PV': 'DOUBLE', 'TIC_3602_SP': 'DOUBLE', 'TIC_3602_VL': 'DOUBLE', 'DT_2203_PV': 'DOUBLE', 'TI_9803_PV': 'DOUBLE', 'DT_2402_PV': 'DOUBLE', 'LI_2101_PV': 'DOUBLE', 'LI_2112_PV': 'DOUBLE', 'LI_6801_PV': 'DOUBLE', 'LI_6101_PV': 'DOUBLE', 'LI_6810_PV': 'DOUBLE', 'SC_1401_PV': 'DOUBLE', 'PT_1422_PV': 'DOUBLE', 'FI_1401_PV': 'DOUBLE', 'SIC_11301_OUT': 'DOUBLE', 'CD_11301_PV': 'DOUBLE', 'FT_11301_PV': 'DOUBLE', 'PT_7917_PV': 'DOUBLE', 'PT_1313_PV': 'DOUBLE', 'CWTOT': 'DOUBLE', 'DI_2203_PV': 'DOUBLE', 'FT_2203_PV': 'DOUBLE', 'FIC_2806_PV': 'DOUBLE'}\n",
      "First Row: {'ID': 1, 'Timestamp': datetime.datetime(2024, 11, 24, 9, 28, 15), 'Source_PLC': 'plc_historian_db_2', 'TI_3801_PV': 87.40239715576172, 'TIC_3111_EXT_PV': 91.13001251220703, 'TIC_3111_EXT_SP': 92.0, 'TIC_3111_EXT_VL': 60.32427215576172, 'TIC_3111B_EXT_PV': 91.13001251220703, 'TIC_3111B_EXT_SP': 92.0, 'TIC_3111B_EXT_VL': 0.0, 'TIC_3121_EXT_PV': 92.74431610107422, 'TIC_3121_EXT_SP': 92.0, 'TIC_3121_EXT_VL': 20.7485408782959, 'TIC_3121B_EXT_PV': 92.74431610107422, 'TIC_3121B_EXT_SP': 92.0, 'TIC_3121B_EXT_VL': -3.299999952316284, 'TIC_3131_EXT_PV': 91.56689453125, 'TIC_3131_EXT_SP': 92.0, 'TIC_3131_EXT_VL': -3.299999952316284, 'TIC_3131B_EXT_PV': 91.56689453125, 'TIC_3131B_EXT_SP': 92.0, 'TIC_3131B_EXT_VL': -1.677860140800476, 'TIC_3141_EXT_PV': 91.66232299804688, 'TIC_3141_EXT_SP': 92.0, 'TIC_3141_EXT_VL': 66.47895050048828, 'TIC_3141B_EXT_PV': 91.66232299804688, 'TIC_3141B_EXT_SP': 92.0, 'TIC_3141B_EXT_VL': 0.0, 'TIC_3601_PV': 89.55223846435547, 'TIC_3601_SP': 90.0, 'TIC_3601_VL': 33.62486267089844, 'TIC_3602_PV': 67.15277862548828, 'TIC_3602_SP': 92.0, 'TIC_3602_VL': 0.0, 'DT_2203_PV': 9.372385025024414, 'TI_9803_PV': 41.45833206176758, 'DT_2402_PV': 8.996292114257812, 'LI_2101_PV': 70.84345245361328, 'LI_2112_PV': 39.644752502441406, 'LI_6801_PV': 38.498958587646484, 'LI_6101_PV': 37.7017936706543, 'LI_6810_PV': 19.23277473449707, 'SC_1401_PV': None, 'PT_1422_PV': 8.724212646484375, 'FI_1401_PV': 28.670242309570312, 'SIC_11301_OUT': 38.0, 'CD_11301_PV': None, 'FT_11301_PV': 43.42454528808594, 'PT_7917_PV': 1.7532196044921875, 'PT_1313_PV': 4.819541931152344, 'CWTOT': 189259488.0, 'DI_2203_PV': None, 'FT_2203_PV': 86.2052001953125, 'FIC_2806_PV': 158.42652893066406}\n",
      "--------------------------------------------------\n",
      "Table: plc_data_3\n",
      "Columns and Data Types: {'ID': 'INTEGER', 'Timestamp': 'DATETIME', 'Source_PLC': 'TEXT', 'TIC_2203_PV': 'DOUBLE', 'FIC_024310B_PV': 'DOUBLE', 'II_2261_PV': 'DOUBLE', 'II_2262_PV': 'DOUBLE', 'TI_2204_PV': 'DOUBLE', 'FI_2204_PV': 'DOUBLE', 'LIC_2403_PV': 'DOUBLE', 'DIC_2402_PV': 'DOUBLE', 'FIC_70101_PV': 'DOUBLE', 'FIC_70102_PV': 'DOUBLE', 'FT_70103_PV': 'DOUBLE', 'FIC_70302_PV': 'DOUBLE', 'FT_70303_PV': 'DOUBLE', 'FIC_70502_PV': 'DOUBLE', 'FIC_6220_PV': 'DOUBLE', 'FIC_70107_PV': 'DOUBLE', 'FIC_70505_PV': 'DOUBLE', 'FT_70503_PV': 'DOUBLE', 'PT_S_PIT_PV': 'DOUBLE', 'ST_70801_PV': 'DOUBLE', 'TIC_2405_PV': 'DOUBLE', 'TIC_2408_PV': 'DOUBLE', 'FIC_2815_PV': 'DOUBLE', 'FIC_12415_PV': 'DOUBLE', 'FERM_GAP_TOT': 'DOUBLE', 'TIC_3601_PV': 'DOUBLE', 'FIC_4107_PV': 'DOUBLE', 'PI_4107_PV': 'DOUBLE', 'LIC_4204_VL': 'DOUBLE', 'FIC_4215_PV': 'DOUBLE', 'FI_6801_PV': 'DOUBLE', 'TI_4410_PV': 'DOUBLE', 'TI_4401_PV': 'DOUBLE', 'TI_DIFF_PV': 'DOUBLE', 'TI_SSDIFF_PV': 'DOUBLE', 'TI_4414_PV': 'DOUBLE', 'TV_2304_PV': 'DOUBLE', 'RECTDIFTMP': 'DOUBLE', 'PI_4501_PV': 'DOUBLE', 'PIC_4511_PV': 'DOUBLE', 'DTFIC_4506_S_PV': 'DOUBLE', 'FI_4505_PV': 'DOUBLE', 'PIC_4621_PV': 'DOUBLE', 'TI_4620_PV': 'DOUBLE', 'FIC_8401_PV': 'DOUBLE', 'TI_4619_PV': 'DOUBLE', 'FI_4613_PV': 'DOUBLE', 'LI_8401_PV': 'DOUBLE', 'LI_8422_PV': 'DOUBLE', 'LI_8433_PV': 'DOUBLE', 'II_6202_PV': 'DOUBLE'}\n",
      "First Row: {'ID': 1, 'Timestamp': datetime.datetime(2024, 11, 24, 9, 28, 15), 'Source_PLC': 'plc_historian_db_3', 'TIC_2203_PV': 184.99826049804688, 'FIC_024310B_PV': 999.7642822265625, 'II_2261_PV': 99.23944854736328, 'II_2262_PV': 239.43362426757812, 'TI_2204_PV': 182.28244018554688, 'FI_2204_PV': 846.1301879882812, 'LIC_2403_PV': 88.99951171875, 'DIC_2402_PV': 9.121980667114258, 'FIC_70101_PV': 806.726318359375, 'FIC_70102_PV': 406.7958984375, 'FT_70103_PV': 566.4873046875, 'FIC_70302_PV': 283.88385009765625, 'FT_70303_PV': 375.4959716796875, 'FIC_70502_PV': 183.07537841796875, 'FIC_6220_PV': 0.0, 'FIC_70107_PV': 48.622650146484375, 'FIC_70505_PV': 165.3280029296875, 'FT_70503_PV': 304.0042724609375, 'PT_S_PIT_PV': 2.444999933242798, 'ST_70801_PV': 0.5, 'TIC_2405_PV': 135.81468200683594, 'TIC_2408_PV': 91.7824935913086, 'FIC_2815_PV': -0.1584930419921875, 'FIC_12415_PV': 3222.1533203125, 'FERM_GAP_TOT': 337.5108947753906, 'TIC_3601_PV': None, 'FIC_4107_PV': 22738.158203125, 'PI_4107_PV': 13.716814994812012, 'LIC_4204_VL': 0.0, 'FIC_4215_PV': 47.38927459716797, 'FI_6801_PV': 223.19935607910156, 'TI_4410_PV': 150.88449096679688, 'TI_4401_PV': 183.46075439453125, 'TI_DIFF_PV': 7.13836669921875, 'TI_SSDIFF_PV': 15.269821166992188, 'TI_4414_PV': 174.95223999023438, 'TV_2304_PV': 0.0, 'RECTDIFTMP': 7.2239532470703125, 'PI_4501_PV': 6.717584133148193, 'PIC_4511_PV': 4.657867431640625, 'DTFIC_4506_S_PV': 148.32139587402344, 'FI_4505_PV': 97.15228271484375, 'PIC_4621_PV': 41.796875, 'TI_4620_PV': 310.1892395019531, 'FIC_8401_PV': 111.8814697265625, 'TI_4619_PV': 276.8135986328125, 'FI_4613_PV': 92.32772064208984, 'LI_8401_PV': 20.417617797851562, 'LI_8422_PV': 32.60416793823242, 'LI_8433_PV': 48.70682907104492, 'II_6202_PV': None}\n",
      "--------------------------------------------------\n",
      "Table: plc_data_4\n",
      "Columns and Data Types: {'ID': 'INTEGER', 'Timestamp': 'DATETIME', 'Source_PLC': 'TEXT', 'FIC_6202_PV': 'DOUBLE', 'C2_DIFF_SPD': 'DOUBLE', 'C2_TORQ': 'DOUBLE', 'II_6203_PV': 'DOUBLE', 'FIC_6203_PV': 'DOUBLE', 'C3_DIFF_SPD': 'DOUBLE', 'C3_TORQ': 'DOUBLE', 'IT_6254_PV': 'DOUBLE', 'FIC_6254_PV': 'DOUBLE', 'C4_DIFF_SPD': 'DOUBLE', 'C4_TORQ': 'DOUBLE', 'FIC_161301_PV': 'DOUBLE', 'WT_161310_PV': 'DOUBLE', 'ZT_161310': 'DOUBLE', 'FIC_161351_PV': 'DOUBLE', 'WT_161360_PV': 'DOUBLE', 'ZT_161360': 'DOUBLE', 'LI_77101_PV': 'DOUBLE', 'LI_77102_PV': 'DOUBLE', 'FI_75802': 'DOUBLE', 'TI_7107_PV': 'DOUBLE', 'TI_7103_PV': 'DOUBLE', 'FI_7102_PV': 'DOUBLE', 'PIC_7102_PV': 'DOUBLE', 'TIC_7311_PV': 'DOUBLE', 'TIC_7311_OUT': 'DOUBLE', 'FT_7306_PV': 'DOUBLE', 'FIC_6811_PV': 'DOUBLE', 'TI_7772_PV': 'DOUBLE', 'TI_7775_PV': 'DOUBLE', 'PI_7751_PV': 'DOUBLE', 'TI_7872_PV': 'DOUBLE', 'TI_7875_PV': 'DOUBLE', 'PI_7851_PV': 'DOUBLE', 'LI_12101_PV': 'DOUBLE', 'LI_12501_PV': 'DOUBLE', 'LI_12410_PV': 'DOUBLE', 'STEAMPERBEER': 'DOUBLE', 'TOT_STM_PERGAL': 'DOUBLE', 'TOTALCOOKWATER': 'DOUBLE', 'FT_70304_PV': 'DOUBLE', 'FT_70504_PV': 'DOUBLE', 'FT4613TOT': 'DOUBLE', 'FIC_6851_PV': 'DOUBLE', 'PT_7930_PV': 'DOUBLE', 'TV_4414_PV': 'DOUBLE', 'DI_4215_PV': 'DOUBLE', 'HT_7311_PV': 'DOUBLE', 'RATE_1401_PV': 'DOUBLE', 'LI_8403_PV': 'DOUBLE', 'LI_2301_PV': 'DOUBLE', 'FT4620_STM': 'DOUBLE', 'FT4107_STM': 'DOUBLE', 'C2_BOWL_CURRENT': 'DOUBLE', 'C3_BOWL_CURRENT': 'DOUBLE', 'SIEVEEFFIC': 'DOUBLE', 'FT1401TOT': 'DOUBLE', 'FT11301TOT': 'DOUBLE', 'FT_70104_PV': 'DOUBLE', 'TV_4414_VL': 'DOUBLE', 'FI_2432_PV': 'DOUBLE', 'DTFT_2402_PV': 'DOUBLE'}\n",
      "First Row: {'ID': 1, 'Timestamp': datetime.datetime(2024, 11, 24, 9, 28, 15), 'Source_PLC': 'plc_historian_db_4', 'FIC_6202_PV': None, 'C2_DIFF_SPD': 6.537463665008545, 'C2_TORQ': 59.0, 'II_6203_PV': None, 'FIC_6203_PV': None, 'C3_DIFF_SPD': 7.995574951171875, 'C3_TORQ': 61.0, 'IT_6254_PV': 91.81381225585938, 'FIC_6254_PV': 159.78480529785156, 'C4_DIFF_SPD': 2.2707157135009766, 'C4_TORQ': 60.0, 'FIC_161301_PV': 163.20797729492188, 'WT_161310_PV': 9.22613525390625, 'ZT_161310': 333.0, 'FIC_161351_PV': 165.94784545898438, 'WT_161360_PV': 9.78094482421875, 'ZT_161360': 342.0, 'LI_77101_PV': 53.787353515625, 'LI_77102_PV': 79.3049545288086, 'FI_75802': 5.245858192443848, 'TI_7107_PV': 202.70738220214844, 'TI_7103_PV': 201.77113342285156, 'FI_7102_PV': 20218.865234375, 'PIC_7102_PV': 45.08850860595703, 'TIC_7311_PV': 213.3822021484375, 'TIC_7311_OUT': 45.572166442871094, 'FT_7306_PV': 26.553466796875, 'FIC_6811_PV': 31.061290740966797, 'TI_7772_PV': 1601.0, 'TI_7775_PV': 362.0, 'PI_7751_PV': -3.1000000000000014, 'TI_7872_PV': 1625.2864990234375, 'TI_7875_PV': 281.0, 'PI_7851_PV': -3.1150975227355957, 'LI_12101_PV': 51.450408935546875, 'LI_12501_PV': 73.00817108154297, 'LI_12410_PV': 69.38704681396484, 'STEAMPERBEER': 38.839820861816406, 'TOT_STM_PERGAL': None, 'TOTALCOOKWATER': 253.8022918701172, 'FT_70304_PV': None, 'FT_70504_PV': None, 'FT4613TOT': None, 'FIC_6851_PV': None, 'PT_7930_PV': None, 'TV_4414_PV': None, 'DI_4215_PV': None, 'HT_7311_PV': None, 'RATE_1401_PV': None, 'LI_8403_PV': None, 'LI_2301_PV': None, 'FT4620_STM': None, 'FT4107_STM': None, 'C2_BOWL_CURRENT': None, 'C3_BOWL_CURRENT': None, 'SIEVEEFFIC': None, 'FT1401TOT': None, 'FT11301TOT': None, 'FT_70104_PV': None, 'TV_4414_VL': None, 'FI_2432_PV': None, 'DTFT_2402_PV': None}\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SQLDatabase\n",
    "# from sqlalchemy import create_engine\n",
    "from dataclasses import dataclass, field\n",
    "from sqlalchemy import inspect, text\n",
    "\n",
    "# Configuration for the database\n",
    "@dataclass\n",
    "class Config:\n",
    "    DB_HOST: str = \"143.198.230.83\"\n",
    "    DB_PORT: int = 3306\n",
    "    DB_NAME: str = \"golgixportal\"\n",
    "    DB_USER: str = \"golgix\"\n",
    "    DB_PASSWORD: str = \"preciseV5\"\n",
    "    ALLOWED_TABLES: list[str] = field(default_factory=lambda: [\n",
    "        \"DE\",\n",
    "        \"HPLC_Data\",\n",
    "        \"fermentation_data\",\n",
    "        \"plc_data_1\",\n",
    "        \"plc_data_2\",\n",
    "        \"plc_data_3\",\n",
    "        \"plc_data_4\"\n",
    "    ])\n",
    "\n",
    "# Load configuration\n",
    "config = Config()\n",
    "\n",
    "# Setup the SQLAlchemy engine URI\n",
    "db_uri = f\"mysql+pymysql://{config.DB_USER}:{config.DB_PASSWORD}@{config.DB_HOST}:{config.DB_PORT}/{config.DB_NAME}\"\n",
    "\n",
    "# Initialize the SQLDatabase with the URI and include_tables parameter\n",
    "sql_database = SQLDatabase.from_uri(db_uri, include_tables=config.ALLOWED_TABLES)\n",
    "engine = sql_database.engine\n",
    "inspector = inspect(engine)\n",
    "\n",
    "include_tables = [\"DE\", \"HPLC_Data\", \"fermentation_data\", \"plc_data_1\", \"plc_data_2\", \"plc_data_3\", \"plc_data_4\"]\n",
    "database_schema = get_first_row_with_types(inspector, include_tables)\n",
    "print(database_schema)\n",
    "# print(len(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CellometerSync', 'DE', 'DE_targets', 'HPLCSync', 'HPLC_Data', 'NIRSync', 'NIR_Data', 'QC', 'QC_targets', 'ab_permission', 'ab_permission_view', 'ab_permission_view_role', 'ab_register_user', 'ab_role', 'ab_user', 'ab_user_role', 'ab_view_menu', 'actual_output', 'alembic_version', 'annotation', 'annotation_layer', 'batch_info_table', 'cache_keys', 'cooks', 'cookshift_comments', 'css_templates', 'dashboard_roles', 'dashboard_slices', 'dashboard_user', 'dashboards', 'database_user_oauth2_tokens', 'dbs', 'de_comments', 'downtime_results', 'dynamic_plugin', 'embedded_dashboards', 'extended_table_to_edit_and_delete', 'fact_finder', 'favstar', 'feature_flag', 'fermentation_batch', 'fermentation_batch_comments', 'fermentation_data', 'inference_output', 'inference_output_deployed_19_02_25', 'key_value', 'keyvalue', 'logs', 'ml_output', 'operators', 'pf_comments', 'plc_categories', 'plc_data_1', 'plc_data_2', 'plc_data_3', 'plc_data_4', 'plc_ips', 'plc_tags', 'predictions', 'propagator_and_fermenter', 'qc_comments', 'query', 'reduced_rate_results', 'report_execution_log', 'report_recipient', 'report_schedule', 'report_schedule_user', 'rls_filter_roles', 'rls_filter_tables', 'row_level_security_filters', 'saved_query', 'shifts', 'shifts1', 'slice_user', 'slices', 'sql_metrics', 'sqlatable_user', 'ssh_tunnels', 'tab_state', 'table_columns', 'table_schema', 'tables', 'tag', 'tagged_object', 'targets', 'user_attribute', 'user_favorite_tag', 'walkthroughs']\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "\n",
    "def get_table_list(sql_database):\n",
    "    \"\"\"Returns a list of all tables in the database.\"\"\"\n",
    "    engine = sql_database.engine  # Extract engine from SQLDatabase\n",
    "    inspector = inspect(engine)\n",
    "    \n",
    "    return inspector.get_table_names()\n",
    "\n",
    "# Example usage\n",
    "table_list = get_table_list(sql_database)\n",
    "print(table_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sufficient': False, 'question': \"Could you please clarify what constitutes a 'load of ethanol'? For example, should we count each production batch or each record with an ethanol value (e.g., '% Ethanol (w/v)' in HPLC_Data) as a load? Additionally, where is the COA (Certificate of Analysis) completion recorded? Is it stored in a specific table or column (perhaps in fermentation_data notes, a COA flag, or another document reference) for the 'other storage tank'?\", 'Assumption': \"I assume that ethanol loads are recorded in one of the production or quality tables (possibly HPLC_Data or fermentation_data) and that a COA indicator should be available, but the provided schema does not clearly define a 'load' or a dedicated COA field.\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from llama_index.core import PromptTemplate\n",
    "import datetime\n",
    "\n",
    "CLARIFICATION_PROMPT = PromptTemplate(\"\"\"\\\n",
    "You are a SQL optimization engineer with deep domain knowledge of industrial equipment systems. Follow this analysis process:\n",
    "\n",
    "1. Schema Mapping:\n",
    "- Identify required tables and the first row of the data from: {schema}\n",
    "- Locate exact column matches for equipment IDs, timestamps, and metrics and understand the meaning based on just the first row given \n",
    "- Verify join paths using foreign keys\n",
    "\n",
    "2. Domain Validation:\n",
    "- Cross-reference {domain_knowledge} thresholds\n",
    "- Confirm failure state calculations align with domain logic\n",
    "\n",
    "3. Join Requirement Check:\n",
    "- Determine if question requires combining operational metrics\n",
    "- Validate time synchronization between tables if joining\n",
    "\n",
    "For question: {question}\n",
    "\n",
    "Response Rules:\n",
    "- Return **ONLY valid JSON** with the following structure:\n",
    "  - If sufficient information:\n",
    "    {{\n",
    "      \"sufficient\": True,\n",
    "      \"question\":  'None'\"\n",
    "      \"Assumption\":Your clear assumption\n",
    "    }}\n",
    "  - If insufficient information:\n",
    "    {{\n",
    "      \"sufficient\": False,\n",
    "      \"question\":  follow up question to generate proper query\n",
    "      \"Assumption\":Your clear assumption\n",
    "    }}\n",
    "\n",
    "Additional Context:\n",
    "- current data time {date}\n",
    "- A SQL engine is available to execute the query and get rest of the data from the tables \n",
    "- If any information is missing or unclear, specify exactly what is needed.\n",
    "\"\"\")\n",
    "\n",
    "def check_sql_feasibility(llm, question, schema, domain_knowledge):\n",
    "    \"\"\"Checks if the given question has enough information to generate SQL.\"\"\"\n",
    "    \n",
    "    schema_str = json.dumps(schema, indent=2)\n",
    "    date=datetime.datetime.now()\n",
    "    response = llm.complete(CLARIFICATION_PROMPT.format(\n",
    "        question=question,\n",
    "        schema=schema_str,\n",
    "        domain_knowledge=domain_knowledge,\n",
    "        date=date,\n",
    "    )).text.strip()\n",
    "\n",
    "    # Ensure the output is properly formatted JSON\n",
    "    try:\n",
    "        json_response = json.loads(response)\n",
    "        return json.dumps(json_response, indent=2)\n",
    "    except json.JSONDecodeError:\n",
    "        return json.dumps({\"error\": \"LLM response is not valid JSON\"}, indent=2)\n",
    "\n",
    "# Example usage\n",
    "# question = \"Tell me total time duration dryer was down in last 7 days equipment_id PT_7930-PV\"\n",
    "# question =\"Downtime on equipment last 24 hours\"\n",
    "question =\"How many loads of ethanol do we have? Is there a COA completed for the other storage tank.\"\n",
    "# question =\"Downtime on all the equipment in last 24 hours\"\n",
    "# question=\"What is the current water balance of the plant.\"\n",
    "# question=\"Are there any deviations from the normal chemical usage levels\"\n",
    "\n",
    "domain_knowledge = \"\"\"\n",
    "PT_7930-PV – DDG suction pressure.  Normal range is -1.9, if suction drops to above -1.0, dryers are down.\n",
    "FIC_70101-PV – FST feed.  Normal range is ~750gpm; low deviation of 20% indicates reduced rate, value of <100 FST is down.\n",
    "FIC_024310B-PV – SMT feed. Normal range is ~1000gpm. Low deviation of 20% indicates reduced rate, value of <100 SMT is down.\n",
    "FIC_6851-PV – Tricanter feed.  Normal range is 60gpm. Low deviation of 20% indicates reduced rate, value of <10gpm tricanter is down.\n",
    "FIC_161351-PV  – Sedicanter feed.  Normal range is 160gpm, Low deviation of 20% indicates reduced rate, value of <50gpm sedicanters down.\n",
    "FI_4505-PV – 190 flow to storage – Normal range is 110gpm.  Low deviation of 20% indicates reduced rate, value of <20gpm distillation down.\n",
    "FIC_8401-PV – Mole sieve feed rate – Normal range is 110gpm. Low deviation of 20% indicates reduced rate, value of <20gpm Mole sieves down.\n",
    "\"\"\"\n",
    "\n",
    "# Run feasibility check\n",
    "llm=llm_openai_o3_200k\n",
    "response_json = json.loads(check_sql_feasibility(llm, question, database_schema, domain_knowledge))\n",
    "print(response_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Could you please clarify what constitutes a 'load of ethanol'? For example, should we count each production batch or each record with an ethanol value (e.g., '% Ethanol (w/v)' in HPLC_Data) as a load? Additionally, where is the COA (Certificate of Analysis) completion recorded? Is it stored in a specific table or column (perhaps in fermentation_data notes, a COA flag, or another document reference) for the 'other storage tank'?\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_json['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many amounts of ethanol being transported or processed in a given system do we have? Also, is there a completed Certificate of Analysis (COA) recorded for the other storage tank, and if so, where is it stored specifically?\n"
     ]
    }
   ],
   "source": [
    "def handle_rephrase(llm, prev_question, prev_feedback, response):      \n",
    "    combine_prompt = f\"\"\"\n",
    "Combine the following into a single, clear question:\n",
    "\n",
    "Original Question: {prev_question}\n",
    "Clarifying Question: {prev_feedback}\n",
    "User's Answer: {response}\n",
    "\n",
    "Rules:\n",
    "1. Preserve the intent of the original question.\n",
    "2. Incorporate the user's answer explicitly.\n",
    "3. Make the question self-contained and unambiguous.\n",
    "4. Return **ONLY valid JSON** in this format:\n",
    "{{\n",
    "    \"question\": \"Your rephrased question here\"\n",
    "}}\n",
    "\n",
    "\"\"\"\n",
    "    result = llm.complete(combine_prompt).text.strip()\n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "llm1 =llm_mistral_large_32k\n",
    "rephrase_que = json.loads(handle_rephrase(\n",
    "    llm=llm1,\n",
    "    prev_question=question,\n",
    "    prev_feedback=response_json['question'],\n",
    "    response=\"the amount of ethanol being transported or processed in a given system\"\n",
    "))\n",
    "print(rephrase_que[\"question\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step get_question\n",
      "Step get_question produced event CustomInputQuestion\n",
      "Running step validate_question\n",
      "question : what can you do ?\n",
      "Enough data to create sql query\n",
      "Step validate_question produced event StopEvent\n",
      "Based on the provided schema details and domain thresholds, I assume you want to optimize SQL queries that join the operational data (such as DE, HPLC_Data, fermentation_data) with the multiple PLC data tables (plc_data_1, plc_data_2, plc_data_3, plc_data_4) using the common timestamp columns and related equipment identifiers. This allows you to calculate the equipment operational states by checking sensor metrics (for example, PT_7930_PV for DDG suction pressure, FIC_70101_PV for FST feed, FIC_024310B_PV for SMT feed, FIC_6851_PV for Tricanter feed, FIC_161351_PV for Sedicanter feed, FI_4505_PV for distillation flow, and FIC_8401_PV for Mole sieve feed rate) against defined thresholds. With a SQL engine available and the current data timestamp noted, I can build or optimize queries that combine these tables, enforce time synchronization, and flag those metrics that fall below their acceptable operational ranges, thereby identifying potential equipment failures.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    InputRequiredEvent,\n",
    "    HumanResponseEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    StopEvent,\n",
    "    StartEvent,\n",
    "    Context\n",
    ")\n",
    "\n",
    "# Define custom events with proper typing\n",
    "class ValidatedQuestionEvent(HumanResponseEvent):\n",
    "    pass\n",
    "\n",
    "# Remove the instruction field if not needed, or make it optional\n",
    "class CustomInputQuestion(InputRequiredEvent):\n",
    "    # Inherits prefix: str from InputRequiredEvent\n",
    "    pass  # Removed instruction field since it's not used\n",
    "\n",
    "class AdditionlInfo(InputRequiredEvent):\n",
    "    pass\n",
    "\n",
    "class RephraseQuestion(HumanResponseEvent):\n",
    "    pass\n",
    "\n",
    "class question_validate_wf(Workflow):\n",
    "    def __init__(self, llm, schema, domain_knowledge,debug=True):\n",
    "        # Remove the self.ctx.set() call from here\n",
    "        super().__init__(timeout=300, verbose=True)\n",
    "        self.llm = llm\n",
    "        self.schema = schema\n",
    "        self.domain_knowledge = domain_knowledge\n",
    "        self.debug=debug\n",
    "    @step\n",
    "    async def get_question(self, ev: StartEvent) -> CustomInputQuestion:\n",
    "        return CustomInputQuestion(prefix=\"Enter your question: \")  # Now valid\n",
    "    \n",
    "    @step\n",
    "    async def validate_question(self,ctx: Context, ev: ValidatedQuestionEvent) -> StopEvent|AdditionlInfo:\n",
    "        if self.debug:\n",
    "            print(\"question :\",ev.response)\n",
    "        ctx.set(\"original_question\",ev.response)\n",
    "        # print(\"schema :\",self.schema)\n",
    "        # print(\"domain :\",self.domain_knowledge)\n",
    "        response_json=json.loads(check_sql_feasibility(self.llm, ev.response, self.schema, self.domain_knowledge))\n",
    "        # print(type(response_json[\"sufficient\"]),response_json[\"sufficient\"])\n",
    "        ctx.set(\"sufficient\",response_json[\"sufficient\"])\n",
    "        ctx.set(\"Assumption\",response_json[\"Assumption\"])\n",
    "        ctx.set(\"Follow_up_Question\",response_json[\"question\"])\n",
    "        if response_json[\"sufficient\"]:\n",
    "            if self.debug:\n",
    "                print(\"Enough data to create sql query\")\n",
    "            return StopEvent(response_json[\"Assumption\"])\n",
    "        else :\n",
    "            if self.debug:\n",
    "                print(\"Not enough data to create sql query follow up question\")\n",
    "            return AdditionlInfo(prefix=response_json[\"question\"])\n",
    "        \n",
    "    @step\n",
    "    async def handle_rephrase(self, ctx: Context,ev: RephraseQuestion) -> StopEvent :\n",
    "        # if self.debug:\n",
    "        #     print(\"question :\",ev.response)\n",
    "        prev_question = await self.ctx.get(\"original_question\")\n",
    "        prev_feedback = await self.ctx.get(\"Follow_up_Question\")\n",
    "        \n",
    "        combine_prompt = f\"\"\"\n",
    "        Original Question: {prev_question}\n",
    "        Clarifying question: {prev_feedback}\n",
    "        User Answer to clarifying question: {ev.response}\n",
    "        \n",
    "        Create a single, clear question that incorporates all the above information.\n",
    "        \n",
    "        Response Rules:\n",
    "        - Return **ONLY valid JSON** with the following structure:\n",
    "        {{\n",
    "        \"sufficient\": True,\n",
    "        \"question\":  'None'\"\n",
    "        \"Assumption\":Your clear assumption\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        return StopEvent(ev.response)\n",
    "        \n",
    "\n",
    "# Execution\n",
    "workflow = question_validate_wf(llm_openai_o3_200k, database_schema, domain_knowledge)\n",
    "handler = workflow.run()\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, CustomInputQuestion):\n",
    "        response = input(event.prefix)\n",
    "        # feedback = {\"valid\": True, \"message\": \"Valid question\"}\n",
    "        \n",
    "        handler.ctx.send_event(\n",
    "            ValidatedQuestionEvent(\n",
    "                response=response,\n",
    "            )\n",
    "        )\n",
    "    elif isinstance(event, AdditionlInfo):\n",
    "        response = input(event.prefix)\n",
    "        # feedback = {\"valid\": True, \"message\": \"Valid question\"}\n",
    "        \n",
    "        handler.ctx.send_event(\n",
    "            RephraseQuestion(\n",
    "                response=response,\n",
    "            )\n",
    "        )\n",
    "\n",
    "final_result = await handler\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from llama_index.core.workflow import (\n",
    "    Event, StartEvent, StopEvent, Workflow, step, \n",
    "    InputRequiredEvent, HumanResponseEvent, Context\n",
    ")\n",
    "\n",
    "# Define events\n",
    "class ValidatedQuestionEvent(Event):\n",
    "    question: str\n",
    "    is_valid: bool\n",
    "    feedback: dict\n",
    "\n",
    "class RefinedQuestionEvent(Event):\n",
    "    question: str\n",
    "\n",
    "class QuestionValidationWorkflow(Workflow):\n",
    "    def __init__(self, llm, schema, domain_knowledge):\n",
    "        # Remove the self.ctx.set() call from here\n",
    "        super().__init__(timeout=300, verbose=True)\n",
    "        self.llm = llm\n",
    "        self.schema = schema\n",
    "        self.domain_knowledge = domain_knowledge\n",
    "\n",
    "    @step\n",
    "    async def validate_question(self, ev: StartEvent) -> ValidatedQuestionEvent | InputRequiredEvent:\n",
    "        # Store original question in context HERE instead\n",
    "        await self.ctx.set(\"original_question\", ev.question)\n",
    "        response = check_sql_feasibility(self.llm, ev.question, self.schema, self.domain_knowledge)\n",
    "        feedback = json.loads(response)\n",
    "        \n",
    "        if feedback.get(\"sufficient\") == \"yes\":\n",
    "            return ValidatedQuestionEvent(\n",
    "                question=ev.question,\n",
    "                is_valid=True,\n",
    "                feedback=feedback\n",
    "            )\n",
    "        else:\n",
    "            return InputRequiredEvent(\n",
    "                prefix=f\"Question: {feedback['question']}\\nAssumption: {feedback['Assumption']}\\nPlease provide additional details: \"\n",
    "            )\n",
    "            \n",
    "    @step\n",
    "    async def handle_validation(self, ev: ValidatedQuestionEvent) -> StopEvent | InputRequiredEvent:\n",
    "        if ev.is_valid:\n",
    "            return StopEvent(result=ev.question)\n",
    "        else:\n",
    "            return InputRequiredEvent(\n",
    "                prefix=f\"Still needs clarification: {ev.feedback['question']}\\nAssumption: {ev.feedback['Assumption']}\\nProvide more details: \"\n",
    "            )\n",
    "    @step\n",
    "    async def refine_question(self, ev: HumanResponseEvent) -> ValidatedQuestionEvent:\n",
    "        prev_question = await self.ctx.get(\"original_question\")\n",
    "        prev_feedback = await self.ctx.get(\"prev_feedback\")\n",
    "        \n",
    "        combine_prompt = f\"\"\"\n",
    "        Original Question: {prev_question}\n",
    "        Previous Feedback: {prev_feedback}\n",
    "        Additional Information: {ev.response}\n",
    "        \n",
    "        Create a single, clear question that incorporates all the above information.\n",
    "        \"\"\"\n",
    "        \n",
    "        refined_question = await self.llm.acomplete(combine_prompt)\n",
    "        refined_question = str(refined_question).strip()\n",
    "        \n",
    "        response = check_sql_feasibility(self.llm, refined_question, self.schema, self.domain_knowledge)\n",
    "        feedback = json.loads(response)\n",
    "        \n",
    "        await self.ctx.set(\"prev_feedback\", feedback)\n",
    "        \n",
    "        return ValidatedQuestionEvent(\n",
    "            question=refined_question,\n",
    "            is_valid=feedback.get(\"sufficient\") == \"yes\",\n",
    "            feedback=feedback\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_interactive(question):\n",
    "    workflow = QuestionValidationWorkflow(llm_openai_o3_200k, database_schema, domain_knowledge)\n",
    "    handler = workflow.run(question=question)\n",
    "    \n",
    "    async for event in handler.stream_events():\n",
    "        if isinstance(event, InputRequiredEvent):\n",
    "            # For Jupyter input\n",
    "            user_input = input(event.prefix)\n",
    "            handler.ctx.send_event(HumanResponseEvent(response=user_input))\n",
    "        elif isinstance(event, ValidatedQuestionEvent):\n",
    "            if event.is_valid:\n",
    "                return event.question\n",
    "            print(\"Still needs refinement...\")\n",
    "        elif isinstance(event, StopEvent):\n",
    "            return event.result\n",
    "            \n",
    "    return await handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step validate_question\n",
      "Final validated question: None\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "from ipywidgets import widgets\n",
    "\n",
    "final_question = await run_interactive(\"Downtime last 24 hours\")\n",
    "print(\"Final validated question:\", final_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whats up\n"
     ]
    }
   ],
   "source": [
    "a = input()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
